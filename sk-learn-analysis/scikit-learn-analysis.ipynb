{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: scikit-learn survey\n",
    "subtitle: Presentation of survey results\n",
    "author:\n",
    "  - name: Inessa Pawson\n",
    "    email: ipawson@openteams.com\n",
    "date: 2024/12/27\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} Libraries and data\n",
    "\n",
    "```python\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/Auslum/scikit_learn_survey/refs/heads/main/scikit-learn-survey-master-dataset.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Future Direction and Priorities\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "# Scikit-learn logo colors (blue and orange)\n",
    "scikit_learn_colors = [\"#0072B2\", \"#FF9900\"]\n",
    "\n",
    "# Generate a color interpolation for the priority levels\n",
    "priority_colors = [\n",
    "    mcolors.to_hex(c)\n",
    "    for c in mcolors.LinearSegmentedColormap.from_list(\"ScikitLearn\", scikit_learn_colors)(np.linspace(0, 1, len(priority_levels)))\n",
    "]\n",
    "\n",
    "# Filter the columns related to the question\n",
    "priority_columns = [col for col in df.columns if \"PROJECT FUTURE DIRECTION AND PRIORITIES\" in col]\n",
    "priority_data = df[priority_columns].dropna()\n",
    "\n",
    "# Rename the categories\n",
    "renamed_columns = [\n",
    "    \"Performance\", \"Reliability\", \"Packaging\", \"New features\",\n",
    "    \"Technical documentation\", \"Educational materials\",\n",
    "    \"Website redesign\", \"Other\"\n",
    "]\n",
    "priority_data.columns = renamed_columns\n",
    "\n",
    "# Prepare data for a stacked bar chart\n",
    "stacked_bar_data = pd.DataFrame({\n",
    "    category: priority_data[category].value_counts().sort_index()\n",
    "    for category in renamed_columns\n",
    "}).fillna(0).astype(int).T\n",
    "\n",
    "priority_levels = [int(level) for level in stacked_bar_data.columns]\n",
    "categories = stacked_bar_data.index\n",
    "\n",
    "# Create the stacked bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bottoms = np.zeros(len(categories))\n",
    "\n",
    "for level, color in zip(priority_levels, priority_colors):\n",
    "    plt.bar(categories, stacked_bar_data[level], bottom=bottoms, label=f'Priority {level}', color=color)\n",
    "    bottoms += stacked_bar_data[level]\n",
    "\n",
    "# Customize the chart\n",
    "plt.title(\"PROJECT FUTURE DIRECTION AND PRIORITIES\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Customize the legend with explanations\n",
    "priority_labels = [\n",
    "    \"1 (Lowest Priority)\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7 (Highest Priority)\"\n",
    "]\n",
    "plt.legend(\n",
    "    labels=priority_labels,\n",
    "    title=\"Level of Priority\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10\n",
    ")\n",
    "\n",
    "# Adjust and display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Spider chart\n",
    "# Prepare data for calculation of weighted averages\n",
    "stacked_bar_data = pd.DataFrame({\n",
    "    category: priority_data[category].value_counts().sort_index()\n",
    "    for category in renamed_columns\n",
    "}).fillna(0).astype(int).T\n",
    "\n",
    "# Calculate weighted averages for each category\n",
    "priority_levels = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "weighted_scores = (stacked_bar_data * priority_levels).sum(axis=1) / stacked_bar_data.sum(axis=1)\n",
    "\n",
    "# Verify new data\n",
    "# print(\"Weighted averages per category:\\n\", weighted_scores)\n",
    "\n",
    "# Prepare the spider chart\n",
    "labels = weighted_scores.index\n",
    "values = weighted_scores.values\n",
    "num_vars = len(labels)\n",
    "\n",
    "# Ensure that the graph is closed (the first value is repeated at the end)\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "values = np.concatenate((values, [values[0]]))\n",
    "angles += angles[:1]\n",
    "\n",
    "# Create the spider chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "ax.fill(angles, values, color='blue', alpha=0.25)\n",
    "ax.plot(angles, values, color='blue', linewidth=2)\n",
    "\n",
    "# Adjust the tags\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels, fontsize=10)\n",
    "ax.set_title(\"PROJECT FUTURE DIRECTION AND PRIORITIES\", fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Show the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Project Future Direction and Priorities](images/chart2.png)\n",
    "***\n",
    "![Project Future Direction and Priorities](images/chart2-2.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Tasks: Priority Levels\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Scikit-learn logo colors (blue and orange)\n",
    "scikit_learn_colors = [\"#0072B2\", \"#FF9900\"]\n",
    "\n",
    "# Generate a color interpolation for the priority levels\n",
    "priority_colors = [\n",
    "    mcolors.to_hex(c)\n",
    "    for c in mcolors.LinearSegmentedColormap.from_list(\"ScikitLearn\", scikit_learn_colors)(np.linspace(0, 1, len(priority_levels)))\n",
    "]\n",
    "\n",
    "# Identify the columns related to the question about priorities for ML tasks\n",
    "ml_task_columns = [\n",
    "    col for col in df.columns\n",
    "    if \"Please order the following ML tasks in order of priority to you\" in col\n",
    "]\n",
    "\n",
    "# Filter relevant data\n",
    "ml_task_data = df[ml_task_columns].dropna()\n",
    "\n",
    "# Rename columns\n",
    "renamed_ml_task_columns = [\n",
    "    \"Regression\", \"Classification\", \"Forecasting\",\n",
    "    \"Outlier/anomaly detection\", \"Dimensionality reduction\",\n",
    "    \"Clustering\", \"Other\"\n",
    "]\n",
    "ml_task_data.columns = renamed_ml_task_columns\n",
    "\n",
    "# Stacked bar chart\n",
    "# Reindex with available priority levels (1 to 7)\n",
    "priority_levels = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Prepare data for the stacked bar chart\n",
    "stacked_bar_data = pd.DataFrame({\n",
    "    category: ml_task_data[category].value_counts().reindex(priority_levels, fill_value=0)\n",
    "    for category in ml_task_data.columns\n",
    "}).T\n",
    "\n",
    "# Create the stacked bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "bottoms = np.zeros(len(stacked_bar_data))\n",
    "\n",
    "# Loop through priority levels and apply custom colors\n",
    "for level, color in zip(priority_levels, priority_colors):\n",
    "    plt.bar(stacked_bar_data.index, stacked_bar_data[level], bottom=bottoms, label=f'Priority {level}', color=color)\n",
    "    bottoms += stacked_bar_data[level]\n",
    "\n",
    "# Customize the chart\n",
    "plt.title(\"ML Tasks: Priority Levels\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Number of Responses\")\n",
    "\n",
    "priority_labels = [\n",
    "    \"1 (Lowest Priority)\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7 (Highest Priority)\"\n",
    "]\n",
    "plt.legend(\n",
    "    labels=priority_labels,\n",
    "    title=\"Priority Level\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10\n",
    ")\n",
    "\n",
    "# Rotate category labels and adjust layout\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Tasks: Priority Levels](images/chart5.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations used to evaluate models\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "def plot_response_counts2(df, column_name, mapping_dict, title, color, y_ax_name):\n",
    "    \"\"\"\n",
    "    General function to plot response counts for survey questions with multiple answers.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The survey data.\n",
    "    column_name (str): The column name containing the responses.\n",
    "    mapping_dict (dict): Dictionary mapping responses in various languages to English categories.\n",
    "    title (str): The title for the graph.\n",
    "    color (str): The color of the bars.\n",
    "    y_ax_name (str): Label for the y-axis.\n",
    "    \"\"\"\n",
    "    # Function to normalize responses using the mapping dictionary\n",
    "    def normalize_responses(response):\n",
    "        if isinstance(response, str):\n",
    "            # Split the responses by comma, strip extra spaces, and map to English categories\n",
    "            response_split = [r.strip() for r in response.split(',')]\n",
    "            normalized = [mapping_dict.get(r, None) for r in response_split]\n",
    "            # Filter out None values (unmapped responses)\n",
    "            return [r for r in normalized if r is not None]\n",
    "        return []\n",
    "\n",
    "    # Apply the normalization to the responses\n",
    "    df['Normalized_Responses'] = df[column_name].apply(normalize_responses)\n",
    "\n",
    "    # Flatten the normalized response lists\n",
    "    all_responses = [item for sublist in df['Normalized_Responses'].dropna() for item in sublist]\n",
    "\n",
    "    # Count the answers and show the number of times each option is chosen\n",
    "    response_counts = pd.Series(all_responses).value_counts()\n",
    "\n",
    "    # Sort the responses from largest to smallest\n",
    "    response_counts = response_counts.sort_values(ascending=True)\n",
    "\n",
    "    # Create the horizontal bar chart\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax = response_counts.plot(kind='barh', color=color)\n",
    "\n",
    "    # Add data tags\n",
    "    for index, value in enumerate(response_counts):\n",
    "        ax.text(value + 2, index, str(value), va='center', ha='left', fontsize=12, fontweight='regular')\n",
    "\n",
    "    # Title and labels\n",
    "    plt.title(title, fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Number of Responses', fontsize=12)\n",
    "    plt.ylabel(y_ax_name, fontsize=12)\n",
    "\n",
    "    # Adjust and show the chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    mapping_dict = {\n",
    "    # Confusion matrix responses\n",
    "    \"Confusion matrix\": \"Confusion matrix\",\n",
    "    \"Matriz de confusão\": \"Confusion matrix\",\n",
    "    \"Matriz de confusión\": \"Confusion matrix\",\n",
    "    \"混淆矩阵\": \"Confusion matrix\",\n",
    "    \"Matrice de confusion\": \"Confusion matrix\",\n",
    "    \"مصفوفة الدقة\": \"Confusion matrix\",\n",
    "    # Reliability diagram responses\n",
    "    \"Reliability diagram\": \"Reliability diagram\",\n",
    "    \"Diagrama de confiabilidade\": \"Reliability diagram\",\n",
    "    \"Diagrama de confiabilidad\": \"Reliability diagram\",\n",
    "    \"可靠性图\": \"Reliability diagram\",\n",
    "    \"Diagramme de fiabilité\": \"Reliability diagram\",\n",
    "    \"مخطط الموثوقية\": \"Reliability diagram\",\n",
    "    # ROC curve responses\n",
    "    \"ROC curve\": \"ROC curve\",\n",
    "    \"Curva ROC\": \"ROC curve\",\n",
    "    \"ROC曲线\": \"ROC curve\",\n",
    "    \"Courbe ROC\": \"ROC curve\",\n",
    "    \"منحنى ROC\": \"ROC curve\",\n",
    "    # Precision-Recall curve responses\n",
    "    \"Precision-Recall curve\": \"Precision-Recall curve\",\n",
    "    \"Curva de Precisão-Recall\": \"Precision-Recall curve\",\n",
    "    \"Curva de Precisión-Recall\": \"Precision-Recall curve\",\n",
    "    \"PR曲线（精确率-召回率曲线）\": \"Precision-Recall curve\",\n",
    "    \"Courbe Précision-Rappel\": \"Precision-Recall curve\",\n",
    "    \"منحنى الدقة-الاسترجاع\": \"Precision-Recall curve\",\n",
    "    # Feature importance responses\n",
    "    \"Feature importance\": \"Feature importance\",\n",
    "    \"Importância das características\": \"Feature importance\",\n",
    "    \"Importancia de variables\": \"Feature importance\",\n",
    "    \"特征重要性\": \"Feature importance\",\n",
    "    \"Importance des caractéristiques (features)\": \"Feature importance\",\n",
    "    \"الأهمية النسبية للخواص\": \"Feature importance\",\n",
    "    # Residual plots responses\n",
    "    \"Residual plots\": \"Residual plots\",\n",
    "    \"Gráficos de resíduos\": \"Residual plots\",\n",
    "    \"Gráficos de residuos\": \"Residual plots\",\n",
    "    \"残差图\": \"Residual plots\",\n",
    "    \"Graphiques des résidus\": \"Residual plots\",\n",
    "    \"مخططات البواقي\": \"Residual plots\",\n",
    "    # Learning curves responses\n",
    "    \"Learning curves\": \"Learning curves\",\n",
    "    \"Curvas de aprendizagem\": \"Learning curves\",\n",
    "    \"Curvas de aprendizaje\": \"Learning curves\",\n",
    "    \"学习曲线\": \"Learning curves\",\n",
    "    \"Courbes d'apprentissage\": \"Learning curves\",\n",
    "    \"منحنيات التعلم\": \"Learning curves\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "plot_response_counts2(\n",
    "    df=df,\n",
    "    column_name='What visualizations do you use to evaluate your models? Select all that apply.',\n",
    "    mapping_dict=mapping_dict,\n",
    "    title='Visualizations used to evaluate models',\n",
    "    color='green',\n",
    "    y_ax_name='Visualizations'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Visualizations used to evaluate models](images/chart6.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe libraries used\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "mapping_dict = {\n",
    "    # cudf responses\n",
    "    \"cudf\": \"cudf\",\n",
    "    \"cuDF كووديف\": \"cudf\",\n",
    "    # Dask DataFrame responses\n",
    "    \"Dask DataFrame\": \"Dask DataFrame\",\n",
    "    \"Dask 数据框\": \"Dask DataFrame\",\n",
    "    \"Dask DataFrame  اطر بيانات داسك\": \"Dask DataFrame\",\n",
    "    # DuckDB responses\n",
    "    \"DuckDB\": \"DuckDB\",\n",
    "    \"DuckDB دك دي بي\": \"DuckDB\",\n",
    "    # Modin responses\n",
    "    \"Modin\": \"Modin\",\n",
    "    \"Modin مودين\": \"Modin\",\n",
    "    # pandas responses\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"Pandas\": \"pandas\",\n",
    "    \"pandas بنداز\": \"pandas\",\n",
    "    # Polars responses\n",
    "    \"Polars\": \"Polars\",\n",
    "    \"Polars بولارز\": \"Polars\",\n",
    "    # Spark DataFrame responses\n",
    "    \"Spark DataFrame\": \"Spark DataFrame\",\n",
    "    \"Spark 数据框\": \"Spark DataFrame\",\n",
    "    \"Spark DataFrame اطر بيانات سبارك\": \"Spark DataFrame\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "plot_response_counts2(\n",
    "    df=df,\n",
    "    column_name='Which DataFrame libraries do you use? Select all that apply.',\n",
    "    mapping_dict=mapping_dict,\n",
    "    title='DataFrame libraries used',\n",
    "    color='blue',\n",
    "    y_ax_name='Libraries'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Dataframe libraries used](images/chart7.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning libraries used\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "mapping_dict = {\n",
    "    # CatBoost responses\n",
    "    \"CatBoost\": \"CatBoost\",\n",
    "    \"CatBoost كات بوست\": \"CatBoost\",\n",
    "    # Jax responses\n",
    "    \"Jax\": \"Jax\",\n",
    "    \"JAX چاكس\": \"Jax\",\n",
    "    # Keras responses\n",
    "    \"Keras\": \"Keras\",\n",
    "    \"Keras كيراس\": \"Keras\",\n",
    "    # LightGBM responses\n",
    "    \"LightGBM\": \"LightGBM\",\n",
    "    \"LightGBM لايت جي بي ام\": \"LightGBM\",\n",
    "    # PyTorch responses\n",
    "    \"PyTorch\": \"PyTorch\",\n",
    "    \"PyTorch باي تورش\": \"PyTorch\",\n",
    "    # Transformers responses\n",
    "    \"Transformers\": \"Transformers\",\n",
    "    \"Transformers المحولات (ترانسفورمرز)\": \"Transformers\",\n",
    "    # XGBoost responses\n",
    "    \"XGBoost\": \"XGBoost\",\n",
    "    \"XGBoost اكس جي بوست\": \"XGBoost\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "plot_response_counts2(\n",
    "    df=df,\n",
    "    column_name='Which other Machine Learning libraries do you use? Select all that apply.',\n",
    "    mapping_dict=mapping_dict,\n",
    "    title='Machine Learning libraries used',\n",
    "    color='orange',\n",
    "    y_ax_name='Libraries'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine Learning libraries used](images/chart9.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators regularly used\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "mapping_dict = {\n",
    "    # LogisticRegression responses\n",
    "    \"LogisticRegression\": \"LogisticRegression\",\n",
    "    \"RandomForestClassifier أو RandomForestRegressorLogisticRegression الانحدار اللوجستي\": \"LogisticRegression\",\n",
    "    # RandomForestClassifier or RandomForestRegressor responses\n",
    "    \"RandomForestClassifier or RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"RandomForestClassifier ou RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"RandomForestClassifier o RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"RandomForestClassifier 或 RandomForestRegressor\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    \"مصنف الغابة العشوائية أو انحدار الغابة العشوائية\": \"RandomForestClassifier or RandomForestRegressor\",\n",
    "    # HistGradientBoostingRegressor or HistGradientBoostingClassifier responses\n",
    "    \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressor ou HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressor o HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressor 或 HistGradientBoostingClassifier\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    \"HistGradientBoostingRegressorأو HistGradientBoostingClassifier  مصنف الانحدار المدعم بتحليل التردد أو شجرة الانحدار المدعمة بتحليل التردد</li>\": \"HistGradientBoostingRegressor or HistGradientBoostingClassifier\",\n",
    "    # Pipeline responses\n",
    "    \"Pipeline\": \"Pipeline\",\n",
    "    \"Pipeline الوصلات \\ خطوط الأنابيب\": \"Pipeline\",\n",
    "    # ColumnTransformer responses\n",
    "    \"ColumnTransformer\": \"ColumnTransformer\",\n",
    "    \"ColumnTransforme محولات الاعمدة\": \"ColumnTransformer\",\n",
    "    # Other responses\n",
    "    \"Other\": \"Other\",\n",
    "    \"Outro\": \"Other\",\n",
    "    \"Otro\": \"Other\",\n",
    "    \"其它\": \"Other\",\n",
    "    \"Autre\": \"Other\",\n",
    "    \"أخرى\": \"Other\"\n",
    "}\n",
    "\n",
    "plot_response_counts2(\n",
    "    df=df,\n",
    "    column_name='Which estimators do you regularly use? Select all that apply.',\n",
    "    mapping_dict=mapping_dict,\n",
    "    title='Estimators Regularly Used',\n",
    "    color='purple',\n",
    "    y_ax_name='Estimators'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estimators regularly used](images/chart10.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ever written an estimator\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(image here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important ML features for use case\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Define the relevant question\n",
    "question_column = \"What ML features are important for your use case? Select all that apply.\"\n",
    "\n",
    "# Check if the column exists in the dataset\n",
    "if question_column in data.columns:\n",
    "    # Count occurrences of each response\n",
    "    response_counts = data[question_column].value_counts()\n",
    "\n",
    "    # Sort responses in the desired order\n",
    "    response_order = [\n",
    "        \"Calibration of probabilistic classifiers\",\n",
    "        \"Calibration of regressors\",\n",
    "        \"Uncertainty estimates for prediction\",\n",
    "        \"Cost-sensitive learning\",\n",
    "        \"Feature importances\",\n",
    "        \"Sample weights\",\n",
    "        \"Metadata routing\",\n",
    "        \"Non-euclidean metrics\"\n",
    "    ]\n",
    "    response_counts = response_counts.reindex(response_order, fill_value=0)\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    response_counts.plot(kind='bar', color='purple')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(\"Responses to the Importance of Open Source ML/AI Frameworks\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Response\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Respondents\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Annotate the bars\n",
    "    for i, count in enumerate(response_counts):\n",
    "        plt.text(i, count + 0.5, str(count), ha='center', fontsize=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{question_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(image here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional information to pass to an estimator\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Extract responses to the question\n",
    "question_column = \"Is there additional information you want to pass to an estimator that is not X and Y?\"\n",
    "if question_column in data.columns:\n",
    "    response_counts = data[question_column].value_counts()\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    response_counts.plot(kind='bar', color=['teal', 'orange'], )\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(\"Responses to Additional Information for Estimator (X and Y)\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Response\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "\n",
    "    # Annotate bars\n",
    "    for i, count in enumerate(response_counts):\n",
    "        plt.text(i, count + 0.5, str(count), ha='center', fontsize=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{question_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Additional information to pass to an estimator](images/chart12.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How critical would GPU capabilities within sk learn be\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "\n",
    "# Identify the columns related to the question about priorities for Deployment\n",
    "deployment_columns = [\n",
    "    col for col in df.columns\n",
    "    if \"Considering your current machine learning projects, how critical would GPU capabilities within scikit-learn be?\" in col\n",
    "]\n",
    "\n",
    "# print(\"Identified columns for Deployment:\\n\",deploy_columns)\n",
    "\n",
    "# Filter relevant data\n",
    "deploy_data = df[deployment_columns].dropna()\n",
    "\n",
    "# Rename columns\n",
    "renamed_deploy_columns = [\n",
    "    \"\"\n",
    "]\n",
    "deploy_data.columns = renamed_deploy_columns\n",
    "\n",
    "# Stacked bar chart\n",
    "# Reindex with available priority levels (1 to 5)\n",
    "priority_levels = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Prepare data for the stacked bar chart\n",
    "stacked_bar_data = pd.DataFrame({\n",
    "    category: deploy_data[category].value_counts().reindex(priority_levels, fill_value=0)\n",
    "    for category in deploy_data.columns\n",
    "}).T\n",
    "\n",
    "# Print to verify processed data\n",
    "#print(\"\\nPrepared data for the stacked bar chart:\")\n",
    "#print(stacked_bar_data)\n",
    "\n",
    "# Create the stacked bar chart\n",
    "stacked_bar_data.plot(\n",
    "    kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"viridis\", edgecolor=\"none\"\n",
    ")\n",
    "plt.title(\"Deployment: Priority Levels\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Number of Responses\")\n",
    "plt.legend(\n",
    "    title=\"Priority Level\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10\n",
    ")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How critical would GPU capabilities within sk learn be](images/chart15.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools used for model registry and experiment tracking\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Define the relevant question\n",
    "question_column = \"For model registry and experiment tracking, do you use any of the following tools? Select all that apply.\"\n",
    "\n",
    "# Check if the column exists in the dataset\n",
    "if question_column in data.columns:\n",
    "    # Count occurrences of each response\n",
    "    response_counts = data[question_column].value_counts()\n",
    "\n",
    "    # Sort responses in the desired order\n",
    "    response_order = [\n",
    "        \"DVC\",\n",
    "        \"Neptune\",\n",
    "        \"MlFlow\",\n",
    "        \"Weight and biases\",\n",
    "        \"Custom tool\",\n",
    "        \"Other\"\n",
    "    ]\n",
    "    response_counts = response_counts.reindex(response_order, fill_value=0)\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    response_counts.plot(kind='bar', color='green')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(\"Responses to the Importance of Open Source ML/AI Frameworks\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Response\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Respondents\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Annotate the bars\n",
    "    for i, count in enumerate(response_counts):\n",
    "        plt.text(i, count + 0.5, str(count), ha='center', fontsize=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{question_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tools used for model registry and experiment tracking](images/chart16.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools used for scheduling\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Define the relevant question\n",
    "question_column = \"For scheduling, do you use any of the following tools? Select all that apply.\"\n",
    "\n",
    "# Check if the column exists in the dataset\n",
    "if question_column in data.columns:\n",
    "    # Count occurrences of each response\n",
    "    response_counts = data[question_column].value_counts()\n",
    "\n",
    "    # Sort responses in the desired order\n",
    "    response_order = [\n",
    "        \"Airflow\",\n",
    "        \"Argo\",\n",
    "        \"Coiled\",\n",
    "        \"Dagster\",\n",
    "        \"Kubeflow\",\n",
    "        \"Metaflow (outerbounds)\",\n",
    "        \"Custom tool\",\n",
    "        \"Other\"\n",
    "    ]\n",
    "    response_counts = response_counts.reindex(response_order, fill_value=0)\n",
    "\n",
    "    # Plot the pie chart\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.pie(response_counts, labels=response_counts.index, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Responses to the Importance of Open Source ML/AI Features\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie chart is drawn as a circle.\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Column '{question_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tools used for scheduling](images/chart17.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time that a typical model training takes in ML projects\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Define the relevant question\n",
    "question_column = \"How long does a typical model training take in your ML projects?\"\n",
    "\n",
    "# Check if the column exists in the dataset\n",
    "if question_column in data.columns:\n",
    "    # Count occurrences of each response\n",
    "    response_counts = data[question_column].value_counts()\n",
    "\n",
    "    # Sort responses in the desired order\n",
    "    response_order = [\n",
    "        \"less than 10 seconds\",\n",
    "        \"less than a minute\",\n",
    "        \"less than 10 minutes\",\n",
    "        \"less than an hour\",\n",
    "        \"less than a day\",\n",
    "        \"more than a day\",\n",
    "    ]\n",
    "    response_counts = response_counts.reindex(response_order, fill_value=0)\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    response_counts.plot(kind='bar', color='blue')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(\"Responses to the Importance of Open Source ML/AI Frameworks\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Response\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Respondents\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Annotate the bars\n",
    "    for i, count in enumerate(response_counts):\n",
    "        plt.text(i, count + 0.5, str(count), ha='center', fontsize=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{question_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Time that a typical model training takes in ML projects](images/chart18.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of deployed models currently mantaining\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "# Identify the columns related to the question about priorities for Deployed Models\n",
    "deployed_models_columns = [\n",
    "    col for col in df.columns\n",
    "    if \"How many deployed models are you (and your team) currently maintaining?\" in col\n",
    "]\n",
    "\n",
    "# print(\"Identified columns for Deployed Models:\\n\",deploy_columns)\n",
    "\n",
    "# Filter relevant data\n",
    "deployed_data = df[deployed_models_columns].dropna()\n",
    "\n",
    "# Rename columns\n",
    "renamed_deployed_columns = [\n",
    "    \"\"\n",
    "]\n",
    "deployed_data.columns = renamed_deployed_columns\n",
    "\n",
    "# Stacked bar chart\n",
    "# Reindex with available priority levels (1 to 5 and more than 5)\n",
    "priority_levels = [1, 2, 3, 4, 5, float('inf')]  # [1, 2, 3, 4, 5, >5]\n",
    "\n",
    "\n",
    "# Prepare data for the stacked bar chart\n",
    "stacked_bar_data = pd.DataFrame({\n",
    "    category: deployed_data[category].value_counts().reindex(priority_levels, fill_value=0)\n",
    "    for category in deployed_data.columns\n",
    "}).T\n",
    "\n",
    "# Print to verify processed data\n",
    "#print(\"\\nPrepared data for the stacked bar chart:\")\n",
    "#print(stacked_bar_data)\n",
    "\n",
    "# Create the stacked bar chart\n",
    "stacked_bar_data.plot(\n",
    "    kind=\"bar\", stacked=True, figsize=(12, 6), colormap=\"viridis\", edgecolor=\"none\"\n",
    ")\n",
    "plt.title(\"Deployment: Priority Levels\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Number of Responses\")\n",
    "plt.legend(\n",
    "    title=\"Priority Level\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=10\n",
    ")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(image here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open source ML & AI frameworks and libraries are crucial for transparency and reproducibility\n",
    "\n",
    "```{dropdown} Show code\n",
    "\n",
    "```python\n",
    "\n",
    "# Define the relevant question\n",
    "question_column = \"To what extent do you agree with the following statement?\\nOpen source ML & AI frameworks and libraries are crucial for ensuring transparency and the reproducibility of AI research and development.\"\n",
    "\n",
    "# Check if the column exists in the dataset\n",
    "if question_column in data.columns:\n",
    "    # Count occurrences of each response\n",
    "    response_counts = data[question_column].value_counts()\n",
    "\n",
    "    # Sort responses in the desired order\n",
    "    response_order = [\n",
    "        \"Strongly agree\",\n",
    "        \"Agree\",\n",
    "        \"Neither agree nor disagree\",\n",
    "        \"Disagree\",\n",
    "        \"Strongly disagree\"\n",
    "    ]\n",
    "    response_counts = response_counts.reindex(response_order, fill_value=0)\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    response_counts.plot(kind='bar', color='red')\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(\"Responses to the Importance of Open Source ML/AI Frameworks\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Response\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Respondents\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Annotate the bars\n",
    "    for i, count in enumerate(response_counts):\n",
    "        plt.text(i, count + 0.5, str(count), ha='center', fontsize=10)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{question_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Open source ML & AI frameworks and libraries are crucial for transparency and reproducibility](images/chart20.png)\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
